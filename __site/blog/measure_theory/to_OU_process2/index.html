<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
   <link rel="stylesheet" href="/libs/katex/katex.min.css">
     
   <link rel="stylesheet" href="/libs/highlight/styles/github.min.css">
   
  <link rel="stylesheet" href="/css/franklin.css">
<link rel="stylesheet" href="/css/hypertext.css">
<link rel="icon" href="/assets/favicon.png">

   <title>Step 6: Stochastic Integration &#40;Itô Integral&#41;</title>  
</head>
<body>
<header>
  <h1 style="color:#283747">Mathematics</h1>
  <nav>
    <a href="/" class="current">Tags</a>
  | <a href="/blog" >Notes</a>
  <hr/>
  </nav>
</header>


<!-- Content appended here -->
<div class="franklin-content"><h2 id="step_6_stochastic_integration_itô_integral"><a href="#step_6_stochastic_integration_itô_integral" class="header-anchor">Step 6: Stochastic Integration &#40;Itô Integral&#41;</a></h2>
<p>The <strong>Itô integral</strong> extends Lebesgue integration to handle integrals like:</p>
\(\int_0^t f(s) \, dB_s\)
<blockquote>
<p><strong>Wait, what&#39;s \(dB_s\)?</strong> This is confusing because the notation looks like \(d\mu\) or \(d\mathbb{P}\) from measure theory&#33; But there&#39;s a crucial difference:</p>
<ul>
<li><p>In Lebesgue integration: \(\int f \, d\mu\) means we&#39;re integrating with respect to a <strong>measure</strong> \(\mu\)</p>
</li>
<li><p>In stochastic integration: \(\int f(s) \, dB_s\) means we&#39;re integrating with respect to <strong>increments of the random process</strong> \(B_s\)</p>
</li>
</ul>
<p>Think of \(dB_s\) as &quot;infinitesimal random noise&quot;—it&#39;s not a measure you can put on sets&#33; Instead, \(dB_s \approx B_{s+ds} - B_s\), which is itself a random variable &#40;approximately \(\mathcal{N}(0, ds)\)&#41;.</p>
<p><strong>The full picture</strong>: The integral \(\int_0^t f(s) \, dB_s\) is itself a <strong>random variable</strong> &#40;depends on the random path \(B_s(\omega)\)&#41;. So we still use measure theory to compute things like \(\mathbb{E}\left[\int_0^t f(s) \, dB_s\right]\), where we integrate with respect to \(\mathbb{P}\)&#33;</p>
</blockquote>
<h3 id="critical_clarification_db_t_is_not_a_measure"><a href="#critical_clarification_db_t_is_not_a_measure" class="header-anchor">CRITICAL CLARIFICATION: \(dB_t\) is NOT a measure&#33;</a></h3>
<p><strong>Your question</strong>: &quot;Can a measurable function be put in place of a measure in the integral?&quot;</p>
<p><strong>Short answer</strong>: <strong>NO&#33;</strong> This is a notational trap. Let me clear this up:</p>
<h4 id="what_is_a_measure"><a href="#what_is_a_measure" class="header-anchor">What IS a measure?</a></h4>
<p>A measure \(\mu\) is a <strong>function that assigns sizes to sets</strong>:</p>
\[\mu: \mathcal{F} \to [0, \infty]\]
\[\mu(\text{set}) = \text{size of that set}\]
<p>Examples:</p>
<ul>
<li><p>Lebesgue measure: \(\lambda([a,b]) = b - a\) &#40;length&#41;</p>
</li>
<li><p>Counting measure: \(\#(A) = \) number of elements in \(A\)</p>
</li>
<li><p>Probability measure: \(\mathbb{P}(A) = \) probability of event \(A\)</p>
</li>
</ul>
<h4 id="what_is_b_t"><a href="#what_is_b_t" class="header-anchor">What is \(B_t\)?</a></h4>
<p>\(B_t\) is a <strong>measurable function</strong> &#40;random variable&#41;:</p>
\[B_t: \Omega \to \mathbb{R}\]
\[B_t(\omega) = \text{position of Brownian particle at time } t \text{ in scenario } \omega\]
<p><strong>Key point</strong>: \(B_t\) takes in an <strong>outcome</strong> \(\omega\) and returns a <strong>number</strong>. It does NOT take in a set and return a size&#33;</p>
<h4 id="so_what_the_heck_is_db_t"><a href="#so_what_the_heck_is_db_t" class="header-anchor">So what the heck is \(dB_t\)?</a></h4>
<p>The notation \(\int f(s) \, dB_s\) is <strong>shorthand</strong> for a completely different construction. It&#39;s defined as:</p>
\[\int_0^t f(s) \, dB_s := \lim_{n \to \infty} \sum_{i=0}^{n-1} f(s_i) \cdot [B_{s_{i+1}} - B_{s_i}]\]
<p>where we partition \([0,t]\) and take a limit.</p>
<p><strong>What&#39;s actually happening</strong>:</p>
<ol>
<li><p>We&#39;re using <strong>function values</strong> \(B_{s_{i+1}} - B_{s_i}\) &#40;numbers, not measures&#33;&#41;</p>
</li>
<li><p>We multiply them by \(f(s_i)\) &#40;also numbers&#41;</p>
</li>
<li><p>We sum up all these products</p>
</li>
<li><p>We take a limit &#40;in \(L^2(\mathbb{P})\)&#41;</p>
</li>
</ol>
<p>This is <strong>NOT</strong> a Lebesgue integral with respect to some measure&#33; It&#39;s a different beast entirely.</p>
<h4 id="the_three_types_of_integrals_in_this_story"><a href="#the_three_types_of_integrals_in_this_story" class="header-anchor">The Three Types of &quot;Integrals&quot; in This Story</a></h4>
<table><tr><th align="right">Type</th><th align="right">Notation</th><th align="right">What it is</th><th align="right">Domain of integration</th></tr><tr><td align="right"><strong>Lebesgue integral</strong></td><td align="right">\(\int_\Omega X \, d\mathbb{P}\)</td><td align="right">Integral w.r.t. <strong>measure</strong> \(\mathbb{P}\)</td><td align="right">Sample space \(\Omega\)</td></tr><tr><td align="right"><strong>Ordinary integral</strong></td><td align="right">\(\int_0^t f(s) \, ds\)</td><td align="right">Lebesgue integral w.r.t. <strong>Lebesgue measure</strong></td><td align="right">Time interval \([0,t] \subset \mathbb{R}\)</td></tr><tr><td align="right"><strong>Itô integral</strong></td><td align="right">\(\int_0^t f(s) \, dB_s\)</td><td align="right"><strong>Limit of sums</strong> using function values</td><td align="right">Time interval \([0,t]\), but weighted by random increments</td></tr></table>
<h4 id="visual_analogy"><a href="#visual_analogy" class="header-anchor">Visual Analogy</a></h4>
<p><strong>Lebesgue integral</strong> \(\int_\Omega X \, d\mathbb{P}\):</p>
<pre><code class="language-julia">Ω &#40;sample space&#41;
├─ A₁ &#40;event&#41;: P&#40;A₁&#41; &#61; 0.3, X&#40;ω&#41; &#61; 5 for ω ∈ A₁
├─ A₂ &#40;event&#41;: P&#40;A₂&#41; &#61; 0.5, X&#40;ω&#41; &#61; 2 for ω ∈ A₂
└─ A₃ &#40;event&#41;: P&#40;A₃&#41; &#61; 0.2, X&#40;ω&#41; &#61; 8 for ω ∈ A₃

∫ X dℙ &#61; 5&#40;0.3&#41; &#43; 2&#40;0.5&#41; &#43; 8&#40;0.2&#41; &#61; weighted average by measure</code></pre>
<p><strong>Itô integral</strong> \(\int_0^t f(s) \, dB_s\):</p>
<pre><code class="language-julia">Time &#91;0,t&#93;, one random path B_s&#40;ω&#41;:
s:    0    0.25   0.5   0.75    1
B_s:  0 ───&gt; 0.3 ──&gt; -0.1 ──&gt; 0.4 ──&gt; 0.2

Increments: ΔB &#61; &#91;0.3, -0.4, 0.5, -0.2&#93; &#40;random numbers&#33;&#41;

∫₀¹ f&#40;s&#41; dB_s ≈ f&#40;0&#41;·&#40;0.3&#41; &#43; f&#40;0.25&#41;·&#40;-0.4&#41; &#43; ... 
              &#61; weighted sum by FUNCTION VALUES, not measure</code></pre>
<h4 id="why_the_notation_is_confusing_but_we_keep_it"><a href="#why_the_notation_is_confusing_but_we_keep_it" class="header-anchor">Why the notation is confusing but we keep it</a></h4>
<p>The notation \(dB_s\) is meant to <strong>evoke</strong> the idea of &quot;infinitesimal increments&quot; of \(B_s\), similar to how \(dx\) suggests infinitesimal increments in \(\int f(x) \, dx\).</p>
<p>But here&#39;s the rub:</p>
<ul>
<li><p>In \(\int f(x) \, dx\), we can interpret \(dx\) as shorthand for Lebesgue measure \(d\lambda(x)\)</p>
</li>
<li><p>In \(\int f(s) \, dB_s\), there is <strong>no measure</strong> \(dB_s\)&#33; The Brownian path is too irregular &#40;nowhere differentiable&#41; to define a measure from it</p>
</li>
</ul>
<p><strong>Bottom line</strong>: \(dB_t\) is <strong>differential notation</strong>, not a measure. The integral is defined by a limit of Riemann-like sums, not via measure theory. We keep the notation because:</p>
<ol>
<li><p>It makes the chain rule &#40;Itô&#39;s formula&#41; look natural</p>
</li>
<li><p>It connects to physics intuition &#40;\(dB_t \sim \sqrt{dt} \cdot \text{noise}\)&#41;</p>
</li>
<li><p>It extends the familiar \(\int f \, dx\) notation</p>
</li>
</ol>
<p>But always remember: <strong>you cannot substitute \(B_t\) for a measure in the abstract Lebesgue integral formula&#33;</strong></p>
<hr />
<h2 id="master_key_always_think_discrete_first"><a href="#master_key_always_think_discrete_first" class="header-anchor">MASTER KEY: Always Think Discrete First&#33;</a></h2>
<p><strong>You just discovered the secret that took me years to learn&#33;</strong> Every time you see an integral in probability or stochastic calculus, <strong>immediately translate it to its discrete version</strong>. The continuous notation is just fancy shorthand.</p>
<h3 id="the_translation_dictionary"><a href="#the_translation_dictionary" class="header-anchor">The Translation Dictionary</a></h3>
<table><tr><th align="right">Continuous &#40;fancy&#41;</th><th align="right">Discrete &#40;clear&#41;</th><th align="right">What it means</th></tr><tr><td align="right">\(\int_\Omega X \, d\mathbb{P}\)</td><td align="right">\(\sum_{i=1}^n X(\omega_i) \cdot \mathbb{P}(\omega_i)\)</td><td align="right">Weighted average over outcomes</td></tr><tr><td align="right">\(\mathbb{E}[X]\)</td><td align="right">\(\sum_{i=1}^n x_i \cdot p_i\)</td><td align="right">Expected value: sum of values × probabilities</td></tr><tr><td align="right">\(\int_0^t f(s) \, ds\)</td><td align="right">\(\sum_{i=0}^{n-1} f(s_i) \cdot \Delta s_i\)</td><td align="right">Area under curve: sum of heights × widths</td></tr><tr><td align="right">\(\int_0^t f(s) \, dB_s\)</td><td align="right">\(\sum_{i=0}^{n-1} f(s_i) \cdot [B_{s_{i+1}} - B_{s_i}]\)</td><td align="right">Sum of values × random increments</td></tr><tr><td align="right">\(dX_t = \mu \, dt + \sigma \, dB_t\)</td><td align="right">\(X_{i+1} = X_i + \mu \cdot \Delta t + \sigma \cdot \Delta B_i\)</td><td align="right">Next value &#61; current &#43; drift &#43; noise</td></tr></table>
<h3 id="example_1_expected_value"><a href="#example_1_expected_value" class="header-anchor">Example 1: Expected Value</a></h3>
<p><strong>Continuous</strong>: \(\mathbb{E}[X] = \int_\Omega X(\omega) \, d\mathbb{P}(\omega)\)</p>
<p><strong>Discrete</strong>: Rolling a die, \(X = \) value shown \(\mathbb{E}[X] = 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + 3 \cdot \frac{1}{6} + 4 \cdot \frac{1}{6} + 5 \cdot \frac{1}{6} + 6 \cdot \frac{1}{6} = 3.5\)</p>
<p>That&#39;s it&#33; The integral is just this sum when \(\Omega\) is continuous.</p>
<h3 id="example_2_variance"><a href="#example_2_variance" class="header-anchor">Example 2: Variance</a></h3>
<p><strong>Continuous</strong>: \(\text{Var}(X) = \int_\Omega [X(\omega) - \mu]^2 \, d\mathbb{P}(\omega)\)</p>
<p><strong>Discrete</strong>: Same die \(\text{Var}(X) = \sum_{i=1}^6 (i - 3.5)^2 \cdot \frac{1}{6} = \frac{(2.5)^2 + (1.5)^2 + (0.5)^2 + (0.5)^2 + (1.5)^2 + (2.5)^2}{6}\)</p>
<h3 id="example_3_brownian_motion_integral"><a href="#example_3_brownian_motion_integral" class="header-anchor">Example 3: Brownian Motion Integral</a></h3>
<p><strong>Continuous</strong>: \(\int_0^1 s \, dB_s\)</p>
<p><strong>Discrete</strong>: Partition \([0,1]\) into \(n\) steps, \(\Delta t = 1/n\), times \(t_i = i/n\) \(\int_0^1 s \, dB_s \approx \sum_{i=0}^{n-1} t_i \cdot [B_{t_{i+1}} - B_{t_i}]\)</p>
<p>Example with \(n=4\) &#40;4 time steps&#41;:</p>
<pre><code class="language-julia">i   t_i    B&#40;t_i&#41;   ΔB_i           Contribution: t_i · ΔB_i
─────────────────────────────────────────────────────────
0   0      0        B&#40;0.25&#41;-0      0 · &#40;B&#40;0.25&#41;&#41;
1   0.25   B&#40;0.25&#41;  B&#40;0.5&#41;-B&#40;0.25&#41; 0.25 · &#40;B&#40;0.5&#41;-B&#40;0.25&#41;&#41;
2   0.5    B&#40;0.5&#41;   B&#40;0.75&#41;-B&#40;0.5&#41; 0.5 · &#40;B&#40;0.75&#41;-B&#40;0.5&#41;&#41;
3   0.75   B&#40;0.75&#41;  B&#40;1&#41;-B&#40;0.75&#41;   0.75 · &#40;B&#40;1&#41;-B&#40;0.75&#41;&#41;
                                    ─────────────────────
                                    Sum ≈ ∫₀¹ s dB_s</code></pre>
<p><strong>Intuition</strong>: We&#39;re computing a weighted sum where:</p>
<ul>
<li><p>Weights &#61; time values \(t_i\) &#40;non-random&#41;</p>
</li>
<li><p>Values &#61; random Brownian increments \(\Delta B_i\) &#40;random&#33;&#41;</p>
</li>
<li><p>Result &#61; a random variable &#40;depends on the random path&#41;</p>
</li>
</ul>
<h3 id="example_4_ornstein-uhlenbeck_the_full_picture"><a href="#example_4_ornstein-uhlenbeck_the_full_picture" class="header-anchor">Example 4: Ornstein-Uhlenbeck &#40;The Full Picture&#33;&#41;</a></h3>
<p><strong>Continuous</strong>: \(dX_t = -\theta X_t \, dt + \sigma \, dB_t\)</p>
<p><strong>Discrete</strong>: Time steps \(\Delta t\), Brownian increments \(\Delta B_i \sim \mathcal{N}(0, \Delta t)\) \(X_{i+1} = X_i + (-\theta X_i) \cdot \Delta t + \sigma \cdot \Delta B_i\) \(= X_i (1 - \theta \Delta t) + \sigma \cdot \Delta B_i\)</p>
<p><strong>Algorithm</strong> &#40;simulation&#41;:</p>
<pre><code class="language-python">X &#61; &#91;X_0&#93;
for i in range&#40;n&#41;:
    drift &#61; -theta * X&#91;i&#93; * dt
    noise &#61; sigma * np.random.randn&#40;&#41; * sqrt&#40;dt&#41;
    X_next &#61; X&#91;i&#93; &#43; drift &#43; noise
    X.append&#40;X_next&#41;</code></pre>
<p>That&#39;s the OU process&#33; Just:</p>
<ul>
<li><p>Drift toward zero: \(-\theta X_i \cdot \Delta t\)</p>
</li>
<li><p>Add random noise: \(\sigma \cdot \Delta B_i\)</p>
</li>
<li><p>Repeat</p>
</li>
</ul>
<p>The SDE notation \(dX_t = -\theta X_t \, dt + \sigma \, dB_t\) is just shorthand for this&#33;</p>
<h3 id="why_this_perspective_is_gold"><a href="#why_this_perspective_is_gold" class="header-anchor">Why This Perspective is Gold</a></h3>
<ol>
<li><p><strong>Debugging</strong>: If a formula seems weird, write out the discrete version. If it doesn&#39;t make sense discretely, you misunderstood something.</p>
</li>
<li><p><strong>Computation</strong>: Every simulation uses the discrete version anyway. The continuous formulas are just for analysis.</p>
</li>
<li><p><strong>Intuition</strong>: Sums are concrete. Integrals are abstract. Always fall back to sums.</p>
</li>
<li><p><strong>Limiting behavior</strong>: The continuous version is just \(\lim_{\Delta t \to 0}\) of the discrete version &#40;when the limit exists&#33;&#41;.</p>
</li>
</ol>
<h3 id="the_pattern"><a href="#the_pattern" class="header-anchor">The Pattern</a></h3>
<p><strong>Every integral in probability/stochastic calculus follows this pattern:</strong></p>
<ol>
<li><p>Start with a discrete sum &#40;finite outcomes, finite time steps&#41;</p>
</li>
<li><p>Make the grid finer: more outcomes, smaller \(\Delta t\)</p>
</li>
<li><p>Take the limit &#40;when it exists&#41;</p>
</li>
<li><p>Give the limit a fancy integral notation</p>
</li>
</ol>
<p><strong>The notation \(\int \cdots d(\cdot)\) is just a compressed representation of a limit of sums.</strong></p>
<p>When you see:</p>
<ul>
<li><p>\(\int f \, d\mathbb{P}\) → Think: \(\sum f(\omega_i) \cdot p_i\)</p>
</li>
<li><p>\(\int f \, ds\) → Think: \(\sum f(s_i) \cdot \Delta s_i\)</p>
</li>
<li><p>\(\int f \, dB_s\) → Think: \(\sum f(s_i) \cdot \Delta B_i\)</p>
</li>
</ul>
<p><strong>Your instinct is 100&#37; correct. Always think discrete first&#33;</strong></p>
<hr />
<h2 id="critical_insight_itô_integrals_are_random_variables_not_numbers"><a href="#critical_insight_itô_integrals_are_random_variables_not_numbers" class="header-anchor">CRITICAL INSIGHT: Itô Integrals are Random Variables, Not Numbers&#33;</a></h2>
<p><strong>This is the mind-bending part</strong>: When you compute \(\int_0^t f(s) \, dB_s\), the result is <strong>not a number</strong>—it&#39;s a <strong>random variable</strong>&#33;</p>
<h3 id="the_type_hierarchy"><a href="#the_type_hierarchy" class="header-anchor">The Type Hierarchy</a></h3>
<p>Let&#39;s be crystal clear about what kind of mathematical object each thing is:</p>
<table><tr><th align="right">Expression</th><th align="right">Type</th><th align="right">Domain</th><th align="right">Output</th></tr><tr><td align="right">\(\mathbb{P}\)</td><td align="right">Measure</td><td align="right">Sets \(A \subseteq \Omega\)</td><td align="right">Numbers in \([0,1]\)</td></tr><tr><td align="right">\(B_t\)</td><td align="right">Random variable &#40;RV&#41;</td><td align="right">Outcomes \(\omega \in \Omega\)</td><td align="right">Numbers in \(\mathbb{R}\)</td></tr><tr><td align="right">\(\int_\Omega X \, d\mathbb{P}\)</td><td align="right">Number</td><td align="right">—</td><td align="right">A single real number</td></tr><tr><td align="right">\(\int_0^t f(s) \, ds\)</td><td align="right">Number</td><td align="right">—</td><td align="right">A single real number</td></tr><tr><td align="right">\(\int_0^t f(s) \, dB_s\)</td><td align="right"><strong>Random variable&#33;</strong></td><td align="right">Outcomes \(\omega \in \Omega\)</td><td align="right">Numbers in \(\mathbb{R}\)</td></tr></table>
<h3 id="why_is_int_0t_fs_db_s_a_random_variable"><a href="#why_is_int_0t_fs_db_s_a_random_variable" class="header-anchor">Why is \(\int_0^t f(s) \, dB_s\) a Random Variable?</a></h3>
<p><strong>Because the Brownian path \(B_s(\omega)\) is random&#33;</strong></p>
<p>Remember the discrete version: \(\int_0^t f(s) \, dB_s \approx \sum_{i=0}^{n-1} f(s_i) \cdot [B_{s_{i+1}}(\omega) - B_{s_i}(\omega)]\)</p>
<p>Each increment \(B_{s_{i+1}}(\omega) - B_{s_i}(\omega)\) depends on the outcome \(\omega\). Different \(\omega\) give different Brownian paths, which give different values of the sum&#33;</p>
<h3 id="concrete_example"><a href="#concrete_example" class="header-anchor">Concrete Example</a></h3>
<p>Take \(\int_0^1 dB_s = B_1 - B_0 = B_1\) &#40;since \(B_0 = 0\)&#41;.</p>
<p>This is <strong>not</strong> a number&#33; It&#39;s the random variable \(B_1\), which:</p>
<ul>
<li><p>Has distribution \(\mathcal{N}(0, 1)\)</p>
</li>
<li><p>Takes different values for different \(\omega\):</p>
<ul>
<li><p>If \(\omega_1\) gives a path that ends at \(B_1(\omega_1) = 0.7\), then \(\int_0^1 dB_s(\omega_1) = 0.7\)</p>
</li>
<li><p>If \(\omega_2\) gives a path that ends at \(B_1(\omega_2) = -1.3\), then \(\int_0^1 dB_s(\omega_2) = -1.3\)</p>
</li>
<li><p>etc.</p>
</li>
</ul>
</li>
</ul>
<p><strong>The integral itself is a function \(\omega \mapsto \text{number}\), i.e., a random variable&#33;</strong></p>
<h3 id="visual_intuition"><a href="#visual_intuition" class="header-anchor">Visual Intuition</a></h3>
<pre><code class="language-julia">Different random outcomes ω:

Outcome ω₁:
   B_s
    |     /\
    |   /    \___     ← Path 1
    |  /         \
    |/_____________s
   0              1
   ∫₀¹ f&#40;s&#41;dB_s&#40;ω₁&#41; &#61; &#40;some number, say 0.45&#41;

Outcome ω₂:
   B_s
    | \
    |  \_     /\      ← Path 2 &#40;different&#33;&#41;
    |    \___/  \
    |____________\s
   0              1
   ∫₀¹ f&#40;s&#41;dB_s&#40;ω₂&#41; &#61; &#40;different number, say -0.73&#41;

Outcome ω₃:
   B_s
    |   ___/\___
    |  /        \     ← Path 3
    | /          \___
    |/_____________s
   0              1
   ∫₀¹ f&#40;s&#41;dB_s&#40;ω₃&#41; &#61; &#40;yet another number, say 0.12&#41;

The integral is the random variable:
I&#40;ω&#41; &#61; ∫₀¹ f&#40;s&#41;dB_s&#40;ω&#41;

which maps outcomes to numbers&#33;</code></pre>
<h3 id="how_to_get_numbers_from_itô_integrals"><a href="#how_to_get_numbers_from_itô_integrals" class="header-anchor">How to Get Numbers from Itô Integrals</a></h3>
<p>To get an actual <strong>number</strong>, you need to either:</p>
<ol>
<li><p><strong>Fix an outcome \(\omega\)</strong> &#40;one realization&#41;: \(\int_0^t f(s) \, dB_s(\omega) = \text{a specific number}\)</p>
</li>
<li><p><strong>Take expectation</strong> &#40;average over all \(\omega\)&#41;: \(\mathbb{E}\left[\int_0^t f(s) \, dB_s\right] = \int_\Omega \left[\int_0^t f(s) \, dB_s(\omega)\right] d\mathbb{P}(\omega)\) This is often \(0\) for Itô integrals&#33;</p>
</li>
<li><p><strong>Compute variance</strong>: \(\text{Var}\left(\int_0^t f(s) \, dB_s\right) = \mathbb{E}\left[\left(\int_0^t f(s) \, dB_s\right)^2\right]\) By Itô isometry: \(= \mathbb{E}\left[\int_0^t f(s)^2 \, ds\right]\)</p>
</li>
<li><p><strong>Compute probability</strong>: \(\mathbb{P}\left(\int_0^t f(s) \, dB_s > 0\right) = \text{a number in } [0,1]\)</p>
</li>
</ol>
<h3 id="the_nested_structure"><a href="#the_nested_structure" class="header-anchor">The Nested Structure</a></h3>
<p>This is why the notation can be so confusing&#33; We have <strong>integrals within integrals</strong>:</p>
\(\mathbb{E}\left[\int_0^t f(s) \, dB_s\right] = \int_\Omega \underbrace{\left[\int_0^t f(s) \, dB_s(\omega)\right]}_{\text{random variable: } \omega \mapsto \text{number}} d\mathbb{P}(\omega)\)
<ul>
<li><p><strong>Inner integral</strong> \(\int_0^t f(s) \, dB_s\): Itô integral, produces a <strong>random variable</strong></p>
</li>
<li><p><strong>Outer integral</strong> \(\int_\Omega \cdots d\mathbb{P}\): Lebesgue integral, produces a <strong>number</strong> &#40;the expected value&#41;</p>
</li>
</ul>
<h3 id="contrast_with_regular_lebesgue_integrals"><a href="#contrast_with_regular_lebesgue_integrals" class="header-anchor">Contrast with Regular Lebesgue Integrals</a></h3>
<p><strong>Lebesgue integral</strong> \(\int_0^t f(s) \, ds\):</p>
<ul>
<li><p>Input: a function \(f: [0,t] \to \mathbb{R}\)</p>
</li>
<li><p>Output: <strong>a number</strong> &#40;the area under the curve&#41;</p>
</li>
<li><p>No randomness&#33; Same answer every time.</p>
</li>
</ul>
<p><strong>Itô integral</strong> \(\int_0^t f(s) \, dB_s\):</p>
<ul>
<li><p>Input: a function \(f\) and a <strong>random path</strong> \(B_s(\omega)\)</p>
</li>
<li><p>Output: <strong>a random variable</strong> &#40;depends on \(\omega\)&#41;</p>
</li>
<li><p>Different answer for each realization&#33;</p>
</li>
</ul>
<h3 id="ornstein-uhlenbeck_example"><a href="#ornstein-uhlenbeck_example" class="header-anchor">Ornstein-Uhlenbeck Example</a></h3>
<p>When we write: \(X_t = X_0 + \int_0^t (-\theta X_s) \, ds + \int_0^t \sigma \, dB_s\)</p>
<ul>
<li><p>First integral: \(\int_0^t (-\theta X_s) \, ds\) is <strong>complicated</strong> &#40;depends on the path \(X_s\)&#41;, but once you know the path, it&#39;s a <strong>number</strong></p>
</li>
<li><p>Second integral: \(\int_0^t \sigma \, dB_s\) is a <strong>random variable</strong> equal to \(\sigma B_t\)</p>
</li>
</ul>
<p>So \(X_t\) itself is a random variable&#33; For each outcome \(\omega\): \(X_t(\omega) = X_0 + \int_0^t (-\theta X_s(\omega)) \, ds + \sigma B_t(\omega)\)</p>
<h3 id="the_mental_model"><a href="#the_mental_model" class="header-anchor">The Mental Model</a></h3>
<p>Think of it this way:</p>
<ol>
<li><p><strong>Before you run the experiment</strong> &#40;\(\omega\) not chosen yet&#41;:</p>
<ul>
<li><p>\(\int_0^t f(s) \, dB_s\) is a random variable &#40;function of \(\omega\)&#41;</p>
</li>
<li><p>You can talk about its distribution, mean, variance</p>
</li>
</ul>
</li>
<li><p><strong>After you run the experiment</strong> &#40;\(\omega\) chosen, one path realized&#41;:</p>
<ul>
<li><p>\(\int_0^t f(s) \, dB_s(\omega)\) is a number</p>
</li>
<li><p>This is what you&#39;d see in a simulation</p>
</li>
</ul>
</li>
<li><p><strong>When you simulate</strong>:</p>
<ul>
<li><p>Generate one Brownian path \(B_s(\omega_1)\)</p>
</li>
<li><p>Compute the sum \(\sum f(s_i) \cdot [B_{s_{i+1}}(\omega_1) - B_{s_i}(\omega_1)]\)</p>
</li>
<li><p>This gives you <strong>one sample</strong> from the random variable</p>
</li>
<li><p>Run it 1000 times to get the distribution&#33;</p>
</li>
</ul>
</li>
</ol>
<p><strong>Bottom line</strong>: \(\int_0^t f(s) \, dB_s\) is a random variable—a function that maps random outcomes to numbers. It&#39;s fundamentally different from \(\int_0^t f(s) \, ds\), which is just a number.</p>
<div class="page-foot">
    Contact me by <a href="mailto:skchu@wustl.edu">E-mail</a> | <a href="https://github.com/kchu25">Github</a> | <a href="https://www.linkedin.com/in/kchu1/">Linkedin</a>
    <br>
    This work is licensed under <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>.  Last modified: October 06, 2025.
    <br>
    Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia language</a>.
</div>
</div><!-- CONTENT ENDS HERE -->
    
        <script src="/libs/katex/katex.min.js"></script>
<script src="/libs/katex/contrib/auto-render.min.js"></script>
<script>renderMathInElement(document.body)</script>

    
    
        <script src="/libs/highlight/highlight.min.js"></script>
<script>hljs.highlightAll();hljs.configure({tabReplace: '    '});</script>

    
  </body>
</html>
